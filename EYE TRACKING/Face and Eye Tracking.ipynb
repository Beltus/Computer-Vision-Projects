{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## import neccessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## path to Face and Eye HaarCascade XML Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "faceCascadePath = '/home/beltus/image/frontalFace10/haarcascade_frontalface_default.xml' \n",
    "eyeCascadePath = '/home/beltus/image/frontalEyes35x16XML/haarcascade_eye.xml'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize the Face and Eye Cascade Classifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Initialize the Face and Eye Cascade Classifier\n",
    "faceCascade  = cv2.CascadeClassifier(faceCascadePath)\n",
    "eyeCascade = cv2.CascadeClassifier(eyeCascadePath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture('video.mp4')\n",
    "\n",
    "\n",
    "while True:\n",
    "    \n",
    "    ret, image = cap.read()\n",
    "    #image=cv2.resize(image,None,fx=0.25,fy=0.25,interpolation=cv2.INTER_AREA)\n",
    "    \n",
    "    image = cv2.resize(image, None, fx=0.5, fy = 0.5, interpolation=cv2.INTER_AREA) #resize image to width of 100 and height of 100 respectively\n",
    "\n",
    "    \n",
    "    cv2.imshow('frame',image)\n",
    "\n",
    "    k = cv2.waitKey(30) & 0xff # press ESC to exit\n",
    "    \n",
    "    if k == 27 or cv2.getWindowProperty('frame', 0)<0:\n",
    "        break\n",
    "        \n",
    "cv2.destroyAllWindows()\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'PIL' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-8c6f9f35af74>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPIL\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfromarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"RGB\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mbuffer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"JPEG\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'PIL' is not defined"
     ]
    }
   ],
   "source": [
    "from io import BytesIO\n",
    "from PIL import *\n",
    "from IPython.display import clear_output, Image, display\n",
    "\n",
    "cap = cv2.VideoCapture('video.mp4')\n",
    "\n",
    "\n",
    "while True:\n",
    "    \n",
    "    ret, frame = cap.read()\n",
    "    img = PIL.Image.fromarray(frame, \"RGB\")\n",
    "    buffer = BytesIO()\n",
    "    img.save(buffer,format=\"JPEG\")        \n",
    "    display(Image(data=buffer.getvalue()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "## activate webcam\n",
    "capture = cv2.VideoCapture(0)\n",
    "\n",
    "#get the frame width and height and convert to integers\n",
    "frame_width = int(capture.get(3))\n",
    "frame_height = int(capture.get(4))\n",
    "\n",
    "# Define the codec and create VideoWriter object.The output is stored in 'outpy.avi' file.\n",
    "out = cv2.VideoWriter('outpy.avi',cv2.VideoWriter_fourcc('M','J','P','G'), 10, (frame_width//2,frame_height//2))\n",
    "\n",
    "## iterate through all the frames (image)\n",
    "while True:\n",
    "    \n",
    "    #read video frame by frame\n",
    "    ret, frame = capture.read()\n",
    "        \n",
    "    #resize frame to half its width and height\n",
    "    resize_frame = cv2.resize(frame, None, fx = 0.5, fy = 0.5, interpolation = cv2.INTER_AREA) #resize image to width of 100 and height of 100 respectively\n",
    "    \n",
    "    #convert resized image to grayscale\n",
    "    gray_frame = cv2.cvtColor(resize_frame, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    ## detect faces in each image\n",
    "    face_rects = faceCascade.detectMultiScale(gray_frame, scaleFactor = 1.05, minNeighbors = 10 , minSize = (30,30))\n",
    "    \n",
    "    #loop over all the detected faces\n",
    "    for (fx, fy, fw , fh) in face_rects:\n",
    "        \n",
    "        #Extract the region of image for which face was detected\n",
    "        face = gray_frame[fy: fy+fh ,  fx: fx+fw ]\n",
    "        \n",
    "        # draw a bounding box around the detected face\n",
    "        drawFace  = cv2.rectangle(resize_frame , (fx, fy) , (fx+fw , fy + fh) , (255, 0, 0), 2) \n",
    "         \n",
    "        #detect the eyes found in the detected faces\n",
    "        eye_rects = eyeCascade.detectMultiScale(face, scaleFactor = 1.05 , minNeighbors = 5 , minSize = (10,10))\n",
    "        \n",
    "        #loop over each detected eye\n",
    "        for (ex, ey, ew , eh) in eye_rects:\n",
    "            \n",
    "            #draw a bounding box around the detected eye\n",
    "            drawEye = cv2.rectangle(resize_frame , (fx + ex , fy + ey) , (fx + ex + ew , fy + ey + eh) , (0 , 255, 0) , 2)\n",
    "            #fX + eX, fY + eY, fX + eX + eW, fY + eY + eH\n",
    "    \n",
    "      # Write the frame into the file 'output.avi'\n",
    "    out.write(resize_frame)\n",
    "    \n",
    "    #show output video\n",
    "    cv2.imshow(\"Tracking...\", resize_frame)\n",
    "        \n",
    "    \n",
    "    #press ESC key to end video\n",
    "    k = cv2.waitKey(30) & 0xff # press ESC to exit\n",
    "    if k == 27:\n",
    "            break\n",
    "            \n",
    "#release camera            \n",
    "capture.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('/home/beltus/image/belt.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#r = cv2.resize(img , (250,250))\n",
    "\n",
    "cv2.imshow(\"frame\" , img)\n",
    "#cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
