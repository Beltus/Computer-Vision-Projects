# -*- coding: utf-8 -*-
"""Classification.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1XizrLYcylTjtu-PYqUkJmzU9AvsN1bUA

# **Hackathon Project to Classify Shopping Items like cloths , shoes etc**

# **Steps to Build our Model**
Time to fire up your Python skills and get your hands dirty. We are finally at the implementation part of our learning!

1. Setting up Google Colab
2. Importing Libraries
3. Loading and Preprocessing Data 
4. Creating a validation set
5. Defining the model structure
6. Training the model 
7. Making predictions
"""

!pip install Pydrive



import  os
from google.colab import drive 
from pydrive.auth import GoogleAuth
from pydrive.drive import GoogleDrive
from google.colab import auth
from oauth2client.client import GoogleCredentials

# Create a drive variable to access Google drive ~Authentification
auth.authenticate_user()
gauth = GoogleAuth();
gauth.credentials = GoogleCredentials.get_application_default()
drive = GoogleDrive(gauth)

# Download the sataset from the google drive
#download  = drive.CreateFile({'id' : 1EU1O3nLcnN72rEspwsBjQIzYDyqk033J'}) # link to the test file in google drive
download = drive.CreateFile({'id' : '1vHk4al7rvM7Wc25rEh5khgTWPa-dOvHD'}) # Link to the training file in google drive
download.GetContentFile('train_LbELtWX.zip') # downloading the data
!unzip train_LbELtWX.zip # unzip the training data

import keras
from keras.models import Sequential
from keras.layers import Dense, Dropout, Flatten
from keras.layers import Conv2D, MaxPooling2D
from keras.utils import to_categorical
from keras.preprocessing import image
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from keras.utils import to_categorical
from tqdm import tqdm

train = pd.read_csv('train.csv') # Read the csv file

# Preprocessing step.

#create list to hold the training images 
train_image = [];

for i in tqdm(range(train.shape[0])):  # Loop thru the total number of images in the training set.tqdm is used to show a progress bar of the iteration of a loop.
      img  = image.load_img('train/'+train['id'][i].astype('str') + '.png' ,  grayscale = True , target_size = (28, 28, 1)) # loads the images from the train.csv file
      img = image.img_to_array(img) ; # converts the img vector to 3D numpy array 
      img = img/ 255 # normalize the grayscale intensities
      train_image.append(img);

X  = np.array(train_image) ;

# We one hot encode the target labels

y = train['label'].values
y = to_categorical(y)# converts the labels int values to binary matrix

"""Creating a Validation Set for Data"""

X_train , X_test , y_train , y_test = train_test_split(X , y , random_state = 42 , test_size = 0.2)

"""# **Defining the Model Structure.**

2 Convolutional Layers

One dense hidden layer

One output Layer
"""

model = Sequential()
model.add(Conv2D(32 , kernel_size = (3 , 3) , activation = 'relu' , input_shape = (28 , 28 , 1)));
model.add(Conv2D(64 , (3 , 3) , activation = 'relu'))
model.add(MaxPooling2D(pool_size = (2 , 2)))
model.add(Dropout(0.25))
model.add(Flatten());
model.add(Dense(128 , activation = 'relu'));
model.add(Dropout(0.5));
model.add(Dense(10 , activation = 'softmax'))

# Compiling the model
model.compile(optimizer = 'Adam' , loss = 'categorical_crossentropy' , metrics = ['accuracy'])

# Training the Model
model.fit(X_train , y_train , epochs = 10 , validation_data = (X_test , y_test) );

download  = drive.CreateFile({'id' : '1EU1O3nLcnN72rEspwsBjQIzYDyqk033J'}) # link to the test file in google drive
download.GetContentFile('test_ScVgIM0.zip')
!unzip test_ScVgIM0.zip

test_file = pd.read_csv('test.csv');

test_img = []

for i in tqdm(range(test.shape[0])):
    img = image.load_img('test/' + test_file['id'][i].astype('str') + '.png' , grayscale = True , target_size = (28 , 28 , 1))
    img = image.img_to_array(img)
    img = img / 255
    test_img.append(img)

test = np.array(test_img);

"""# **Prediction**"""

# Prediction
prediction = model.predict_classes(test);

download = drive.CreateFile({'id': '1IHHTAc0ugppZ7kEza9aEycYYCJc05pbs'})
download.GetContentFile('sample_submission_I5njJSF.csv')

sample = pd.read_csv('sample_submission_I5njJSF.csv')
sample['id'] = test_file['id']
sample['label'] = prediction
sample.to_csv('sample.csv', header=True, index=False)

"""# **Saving .csv file to drive from google collab**"""

drive.mount('drive')
!cp sample.csv drive/My\ Drive/